{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Global Earthquake Data (2002-2025)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook presents a comprehensive Exploratory Data Analysis (EDA) of earthquake data from the USGS database, covering the period 2002-2025. The analysis aims to understand patterns, distributions, and relationships within seismic activity data.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Assess Data Quality** - Identify missing values, outliers, and data consistency issues\n",
    "2. **Understand Distributions** - Analyze the distribution of key seismic variables (Magnitude, Depth)\n",
    "3. **Discover Temporal & Spatial Patterns** - Find patterns in earthquake occurrences over time and geography\n",
    "4. **Identify Relationships** - Examine correlations between variables\n",
    "5. **Apply Dimensionality Reduction** - Use PCA for pattern discovery\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "- **Source:** USGS Earthquake Database\n",
    "- **Period:** 2002-2025\n",
    "- **File:** `final_earthquake_data_2002_2025.csv`\n",
    "\n",
    "### Key Deliverables (marked with stars)\n",
    "\n",
    "| Deliverable | Description |\n",
    "|-------------|-------------|\n",
    "| Magnitude Histogram | Distribution visualization of earthquake magnitudes |\n",
    "| Depth Scatter Plot | Depth distribution and Depth vs Magnitude relationship |\n",
    "| Correlation Matrix | Heatmap showing relationships between numerical variables |\n",
    "| PCA Analysis | Dimensionality reduction and feature importance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Setup and Imports\n",
    "\n",
    "First, we import all necessary libraries and configure global settings for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "\n",
    "# Machine learning (PCA)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set global plot styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# File paths\n",
    "DATA_PATH = '../data/processed/final_earthquake_data_2002_2025.csv'\n",
    "OUTPUT_DIR = '../outputs/figures/'\n",
    "\n",
    "# Figure settings\n",
    "FIGSIZE_SMALL = (8, 6)\n",
    "FIGSIZE_MEDIUM = (12, 8)\n",
    "FIGSIZE_LARGE = (16, 10)\n",
    "FIGSIZE_XLARGE = (20, 12)\n",
    "\n",
    "# Column groups for analysis\n",
    "NUMERICAL_COLS = ['Latitude', 'Longitude', 'Depth', 'Magnitude',\n",
    "                  'nst', 'gap', 'rms', 'horizontalError', 'depthError',\n",
    "                  'year', 'month', 'day', 'hour', 'energy']\n",
    "CATEGORICAL_COLS = ['magnitude_category', 'depth_category', 'magType',\n",
    "                    'type', 'status', 'net']\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Data Loading\n",
    "\n",
    "We load the earthquake dataset and perform initial inspection to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['Timestamp', 'updated'])\n",
    "print(f\"Data loaded: {df.shape[0]:,} rows x {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(\"=\"*60)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal Records: {df.shape[0]:,}\")\n",
    "print(f\"Total Columns: {df.shape[1]}\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "print(f\"Time Period: {df['year'].min()} - {df['year'].max()}\")\n",
    "\n",
    "print(\"\\nColumn Types:\")\n",
    "for dtype, count in df.dtypes.value_counts().items():\n",
    "    print(f\"  - {dtype}: {count}\")\n",
    "\n",
    "print(f\"\\nNumerical Columns ({len(df.select_dtypes(include=[np.number]).columns)})\")\n",
    "print(f\"Categorical Columns ({len(df.select_dtypes(include=['object', 'category']).columns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics - Numerical\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics - Categorical\n",
    "df.describe(include=['object', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview Insights\n",
    "\n",
    "**Key Observations:**\n",
    "- The dataset contains nearly **3 million earthquake records** spanning 2002-2025\n",
    "- **28 columns** including spatial coordinates (Latitude, Longitude), seismic metrics (Magnitude, Depth), quality indicators, and derived categories\n",
    "- Data types include numerical (float64, int64), categorical (object), and datetime columns\n",
    "- The dataset uses approximately **2.2 GB** of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Data Quality Assessment\n",
    "\n",
    "Before analysis, we must assess data quality including missing values, duplicates, and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_count = df.isnull().sum()\n",
    "missing_pct = (missing_count / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_count.index,\n",
    "    'Missing Count': missing_count.values,\n",
    "    'Missing Percentage': missing_pct.values\n",
    "}).sort_values('Missing Percentage', ascending=False)\n",
    "\n",
    "# Show columns with missing values\n",
    "missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
    "print(\"Columns with Missing Values:\")\n",
    "print(missing_cols.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_cols) > 0:\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_MEDIUM)\n",
    "    bars = ax.barh(missing_cols['Column'], missing_cols['Missing Percentage'], color='coral')\n",
    "    ax.set_xlabel('Missing Percentage (%)')\n",
    "    ax.set_ylabel('Column')\n",
    "    ax.set_title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for bar, pct in zip(bars, missing_cols['Missing Percentage']):\n",
    "        ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "               f'{pct:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}missing_values.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"=\"*60)\n",
    "print(\"DUPLICATE RECORDS CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Exact Duplicates: {df.duplicated().sum():,}\")\n",
    "print(f\"Duplicates by Key Fields (Timestamp, Lat, Lon, Mag): {df.duplicated(subset=['Timestamp', 'Latitude', 'Longitude', 'Magnitude']).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data consistency validation\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CONSISTENCY VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Latitude range\n",
    "lat_valid = df['Latitude'].between(-90, 90).all()\n",
    "print(f\"Latitude Range [-90, 90]: {'Valid' if lat_valid else 'Invalid'}\")\n",
    "\n",
    "# Longitude range\n",
    "lon_valid = df['Longitude'].between(-180, 180).all()\n",
    "print(f\"Longitude Range [-180, 180]: {'Valid' if lon_valid else 'Invalid'}\")\n",
    "\n",
    "# Depth check\n",
    "depth_negative = (df['Depth'] < 0).sum()\n",
    "print(f\"Depth >= 0: {depth_negative} negative values\")\n",
    "\n",
    "# Magnitude check\n",
    "mag_outliers = df[~df['Magnitude'].between(-2, 10)].shape[0]\n",
    "print(f\"Magnitude Range [-2, 10]: {mag_outliers:,} outliers\")\n",
    "\n",
    "# Year check\n",
    "year_valid = df['year'].between(2002, 2025).all()\n",
    "print(f\"Year Range [2002, 2025]: {'Valid' if year_valid else 'Invalid'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "outlier_cols = ['Magnitude', 'Depth', 'energy']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in outlier_cols:\n",
    "    if col in df.columns:\n",
    "        data = df[col].dropna()\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)).sum()\n",
    "        print(f\"{col}: {outliers:,} outliers ({(outliers/len(data))*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for outlier visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "for ax, col in zip(axes, outlier_cols):\n",
    "    if col in df.columns:\n",
    "        df.boxplot(column=col, ax=ax)\n",
    "        ax.set_title(f'{col}', fontsize=12)\n",
    "        ax.set_ylabel('Value')\n",
    "\n",
    "plt.suptitle('Outlier Detection - Box Plots', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}outliers_boxplot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Insights\n",
    "\n",
    "**Missing Values:**\n",
    "- `depthError` has the highest missing rate (~7.2%)\n",
    "- `rms` (root mean square residual) has ~3.9% missing\n",
    "- Core variables (`Magnitude`, `Depth`) have minimal missing values (<2%)\n",
    "\n",
    "**Data Consistency:**\n",
    "- Geographic coordinates (Latitude, Longitude) are within valid ranges\n",
    "- Some magnitude values fall outside typical range (-2 to 10), likely representing special event types\n",
    "- No exact duplicates found, though some events share timestamp/location\n",
    "\n",
    "**Outliers:**\n",
    "- Magnitude outliers (~8.7%) represent extreme events and should be retained for analysis\n",
    "- Depth outliers (~14.7%) include both very shallow and very deep earthquakes\n",
    "- Energy outliers (~21.5%) are expected due to the exponential nature of energy release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Univariate Analysis\n",
    "\n",
    "Analyzing the distribution of individual variables to understand their characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Magnitude Distribution (Key Deliverable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitude statistics\n",
    "mag_data = df['Magnitude'].dropna()\n",
    "\n",
    "mag_stats = {\n",
    "    'mean': mag_data.mean(),\n",
    "    'median': mag_data.median(),\n",
    "    'std': mag_data.std(),\n",
    "    'min': mag_data.min(),\n",
    "    'max': mag_data.max(),\n",
    "    'skewness': stats.skew(mag_data),\n",
    "    'kurtosis': stats.kurtosis(mag_data)\n",
    "}\n",
    "\n",
    "print(\"Magnitude Statistics:\")\n",
    "for key, value in mag_stats.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitude Distribution Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_LARGE)\n",
    "\n",
    "# Subplot 1: Histogram with KDE\n",
    "ax1 = axes[0]\n",
    "ax1.hist(mag_data, bins=30, density=True, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "mag_data.plot(kind='kde', ax=ax1, color='red', linewidth=2, label='KDE')\n",
    "ax1.axvline(mag_stats['mean'], color='green', linestyle='--', linewidth=2, label=f\"Mean: {mag_stats['mean']:.2f}\")\n",
    "ax1.axvline(mag_stats['median'], color='orange', linestyle='--', linewidth=2, label=f\"Median: {mag_stats['median']:.2f}\")\n",
    "ax1.set_xlabel('Magnitude')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Magnitude Distribution (Histogram + KDE)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "\n",
    "# Subplot 2: Boxplot\n",
    "ax2 = axes[1]\n",
    "bp = ax2.boxplot(mag_data, vert=True, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "ax2.set_ylabel('Magnitude')\n",
    "ax2.set_title('Magnitude Boxplot', fontsize=12, fontweight='bold')\n",
    "\n",
    "quartiles = mag_data.quantile([0.25, 0.5, 0.75])\n",
    "ax2.annotate(f\"Q1: {quartiles[0.25]:.2f}\", xy=(1.1, quartiles[0.25]), fontsize=9)\n",
    "ax2.annotate(f\"Q2: {quartiles[0.5]:.2f}\", xy=(1.1, quartiles[0.5]), fontsize=9)\n",
    "ax2.annotate(f\"Q3: {quartiles[0.75]:.2f}\", xy=(1.1, quartiles[0.75]), fontsize=9)\n",
    "\n",
    "# Subplot 3: Category bar chart\n",
    "ax3 = axes[2]\n",
    "if 'magnitude_category' in df.columns:\n",
    "    cat_order = ['Micro', 'Minor', 'Small', 'Light', 'Moderate', 'Strong', 'Major', 'Great']\n",
    "    cat_counts = df['magnitude_category'].value_counts()\n",
    "    cat_counts = cat_counts.reindex([c for c in cat_order if c in cat_counts.index])\n",
    "    bars = ax3.bar(cat_counts.index, cat_counts.values, color=plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(cat_counts))))\n",
    "    ax3.set_xlabel('Magnitude Category')\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.set_title('Earthquake Counts by Category', fontsize=12, fontweight='bold')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax3.annotate(f'{int(height):,}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Magnitude Distribution Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}magnitude_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude Distribution Insights\n",
    "\n",
    "**Key Findings:**\n",
    "- The magnitude distribution is **right-skewed** (skewness = 0.85), indicating most earthquakes are smaller magnitude\n",
    "- **Mean magnitude: 1.72**, **Median: 1.40** - the difference confirms positive skew\n",
    "- The distribution roughly follows the **Gutenberg-Richter law**: frequency decreases exponentially with magnitude\n",
    "- **97.4% of earthquakes are classified as \"Small\"** (magnitude < 4)\n",
    "- Major earthquakes (M >= 7.0) are extremely rare (323 events, 0.01%)\n",
    "\n",
    "**Seismological Interpretation:**\n",
    "- Small earthquakes occur frequently and continuously\n",
    "- Large earthquakes are rare but release significantly more energy\n",
    "- The skewed distribution is characteristic of natural earthquake populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Depth Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth Distribution Visualization\n",
    "depth_data = df['Depth'].dropna()\n",
    "\n",
    "depth_stats = {\n",
    "    'mean': depth_data.mean(),\n",
    "    'median': depth_data.median(),\n",
    "    'std': depth_data.std(),\n",
    "    'min': depth_data.min(),\n",
    "    'max': depth_data.max()\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_LARGE)\n",
    "\n",
    "# Histogram with KDE\n",
    "ax1 = axes[0]\n",
    "ax1.hist(depth_data, bins=50, density=True, alpha=0.7, color='teal', edgecolor='black')\n",
    "depth_data.plot(kind='kde', ax=ax1, color='red', linewidth=2, label='KDE')\n",
    "ax1.axvline(depth_stats['mean'], color='green', linestyle='--', linewidth=2, label=f\"Mean: {depth_stats['mean']:.1f}\")\n",
    "ax1.set_xlabel('Depth (km)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Depth Distribution (Histogram + KDE)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "\n",
    "# Boxplot\n",
    "ax2 = axes[1]\n",
    "bp = ax2.boxplot(depth_data, vert=True, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightgreen')\n",
    "ax2.set_ylabel('Depth (km)')\n",
    "ax2.set_title('Depth Boxplot', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Category bar chart\n",
    "ax3 = axes[2]\n",
    "if 'depth_category' in df.columns:\n",
    "    cat_counts = df['depth_category'].value_counts()\n",
    "    cat_order = ['Shallow', 'Intermediate', 'Deep', 'Very Deep']\n",
    "    cat_counts = cat_counts.reindex([c for c in cat_order if c in cat_counts.index])\n",
    "    colors = ['#90EE90', '#FFD700', '#FFA500', '#FF4500'][:len(cat_counts)]\n",
    "    bars = ax3.bar(cat_counts.index, cat_counts.values, color=colors)\n",
    "    ax3.set_xlabel('Depth Category')\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.set_title('Earthquake Counts by Depth Category', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax3.annotate(f'{int(height):,}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Depth Distribution Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}depth_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDepth Statistics:\")\n",
    "print(f\"  Mean: {depth_stats['mean']:.2f} km\")\n",
    "print(f\"  Median: {depth_stats['median']:.2f} km\")\n",
    "print(f\"  Range: {depth_stats['min']:.2f} - {depth_stats['max']:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth Distribution Insights\n",
    "\n",
    "**Key Findings:**\n",
    "- Most earthquakes are **shallow** (depth < 70 km), comprising ~90% of events\n",
    "- **Mean depth: 24.8 km**, **Median: 8.6 km** - indicating heavy concentration at shallow depths\n",
    "- Maximum depth recorded: **735.8 km** (deep subduction zone earthquakes)\n",
    "\n",
    "**Geological Interpretation:**\n",
    "- **Shallow earthquakes** (0-70 km): Most common, occur in Earth's crust and upper mantle\n",
    "- **Intermediate depth** (70-300 km): Associated with subduction zones\n",
    "- **Deep earthquakes** (>300 km): Rare, occur in descending oceanic plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Categorical Variable Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical distributions\n",
    "cat_cols = ['magnitude_category', 'depth_category', 'magType', 'type', 'status', 'net']\n",
    "available_cols = [col for col in cat_cols if col in df.columns]\n",
    "\n",
    "n_cols = len(available_cols)\n",
    "n_rows = (n_cols + 2) // 3\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(16, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(available_cols):\n",
    "    ax = axes[idx]\n",
    "    value_counts = df[col].value_counts().head(10)\n",
    "    bars = ax.barh(value_counts.index, value_counts.values, color=plt.cm.Set3(np.linspace(0, 1, len(value_counts))))\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2, f'{int(width):,}',\n",
    "               ha='left', va='center', fontsize=8)\n",
    "\n",
    "for idx in range(len(available_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Categorical Variable Distributions', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}categorical_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Bivariate Analysis\n",
    "\n",
    "Examining relationships between pairs of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Depth vs Magnitude (Key Deliverable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "df_clean = df[['Depth', 'Magnitude', 'magnitude_category']].dropna()\n",
    "\n",
    "pearson_corr, pearson_p = stats.pearsonr(df_clean['Depth'], df_clean['Magnitude'])\n",
    "spearman_corr, spearman_p = stats.spearmanr(df_clean['Depth'], df_clean['Magnitude'])\n",
    "\n",
    "print(\"Depth vs Magnitude Correlations:\")\n",
    "print(f\"  Pearson r: {pearson_corr:.4f} (p-value: {pearson_p:.2e})\")\n",
    "print(f\"  Spearman rho: {spearman_corr:.4f} (p-value: {spearman_p:.2e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth vs Magnitude Scatter Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=FIGSIZE_LARGE)\n",
    "\n",
    "# Sample for visualization\n",
    "if len(df_clean) > 50000:\n",
    "    df_sample = df_clean.sample(n=50000, random_state=42)\n",
    "else:\n",
    "    df_sample = df_clean\n",
    "\n",
    "# Subplot 1: Scatter by category\n",
    "ax1 = axes[0]\n",
    "cat_order = ['Micro', 'Minor', 'Small', 'Light', 'Moderate', 'Strong', 'Major', 'Great']\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.1, 0.9, len(cat_order)))\n",
    "color_map = {cat: colors[i] for i, cat in enumerate(cat_order)}\n",
    "\n",
    "for cat in cat_order:\n",
    "    if cat in df_sample['magnitude_category'].unique():\n",
    "        subset = df_sample[df_sample['magnitude_category'] == cat]\n",
    "        ax1.scatter(subset['Depth'], subset['Magnitude'],\n",
    "                   alpha=0.5, s=10, label=cat, color=color_map.get(cat, 'gray'))\n",
    "\n",
    "ax1.set_xlabel('Depth (km)', fontsize=12)\n",
    "ax1.set_ylabel('Magnitude', fontsize=12)\n",
    "ax1.set_title('Depth vs Magnitude (by Category)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(title='Category', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "corr_text = f\"Pearson r = {pearson_corr:.4f}\\nSpearman rho = {spearman_corr:.4f}\"\n",
    "ax1.text(0.05, 0.95, corr_text, transform=ax1.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Subplot 2: Hexbin density\n",
    "ax2 = axes[1]\n",
    "hb = ax2.hexbin(df_clean['Depth'], df_clean['Magnitude'],\n",
    "                gridsize=50, cmap='YlOrRd', mincnt=1)\n",
    "ax2.set_xlabel('Depth (km)', fontsize=12)\n",
    "ax2.set_ylabel('Magnitude', fontsize=12)\n",
    "ax2.set_title('Depth vs Magnitude (Density)', fontsize=12, fontweight='bold')\n",
    "cb = plt.colorbar(hb, ax=ax2)\n",
    "cb.set_label('Count')\n",
    "\n",
    "# Regression line\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['Depth'], df_clean['Magnitude'])\n",
    "x_line = np.array([df_clean['Depth'].min(), df_clean['Depth'].max()])\n",
    "y_line = slope * x_line + intercept\n",
    "ax2.plot(x_line, y_line, 'b--', linewidth=2, label=f'Regression: y={slope:.4f}x+{intercept:.2f}')\n",
    "ax2.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Depth vs Magnitude Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}depth_vs_magnitude_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth vs Magnitude Insights\n",
    "\n",
    "**Key Findings:**\n",
    "- **Moderate positive correlation**: Pearson r = 0.35, Spearman rho = 0.44\n",
    "- Deeper earthquakes tend to have higher magnitudes on average\n",
    "- The density plot shows concentration of small, shallow earthquakes (lower left)\n",
    "\n",
    "**Seismological Interpretation:**\n",
    "- Shallow earthquakes span the full magnitude range (from micro to great)\n",
    "- Deep earthquakes (>300 km) rarely have very low magnitudes due to detection limits\n",
    "- The relationship is partly due to observational bias: small deep earthquakes are harder to detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Pattern Analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=FIGSIZE_XLARGE)\n",
    "\n",
    "# Yearly counts\n",
    "ax1 = axes[0, 0]\n",
    "yearly_counts = df.groupby('year').size()\n",
    "ax1.plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2, markersize=4)\n",
    "ax1.fill_between(yearly_counts.index, yearly_counts.values, alpha=0.3)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Earthquake Count')\n",
    "ax1.set_title('Earthquakes per Year', fontsize=12, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly pattern\n",
    "ax2 = axes[0, 1]\n",
    "monthly_counts = df.groupby('month').size()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "ax2.bar(monthly_counts.index, monthly_counts.values, color='steelblue')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Earthquake Count')\n",
    "ax2.set_title('Earthquakes by Month (All Years)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(range(1, 13))\n",
    "ax2.set_xticklabels(month_names, rotation=45)\n",
    "\n",
    "# Day of week\n",
    "ax3 = axes[0, 2]\n",
    "if 'dayofweek' in df.columns:\n",
    "    dow_counts = df.groupby('dayofweek').size()\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    ax3.bar(dow_counts.index, dow_counts.values, color='teal')\n",
    "    ax3.set_xlabel('Day of Week')\n",
    "    ax3.set_ylabel('Earthquake Count')\n",
    "    ax3.set_title('Earthquakes by Day of Week', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xticks(range(7))\n",
    "    ax3.set_xticklabels(day_names)\n",
    "\n",
    "# Hourly distribution\n",
    "ax4 = axes[1, 0]\n",
    "hourly_counts = df.groupby('hour').size()\n",
    "ax4.bar(hourly_counts.index, hourly_counts.values, color='coral')\n",
    "ax4.set_xlabel('Hour (UTC)')\n",
    "ax4.set_ylabel('Earthquake Count')\n",
    "ax4.set_title('Earthquakes by Hour', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Year x Month heatmap\n",
    "ax5 = axes[1, 1]\n",
    "pivot_table = df.groupby(['year', 'month']).size().unstack(fill_value=0)\n",
    "sns.heatmap(pivot_table, cmap='YlOrRd', ax=ax5, cbar_kws={'label': 'Count'})\n",
    "ax5.set_xlabel('Month')\n",
    "ax5.set_ylabel('Year')\n",
    "ax5.set_title('Year x Month Heatmap', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Average magnitude by year\n",
    "ax6 = axes[1, 2]\n",
    "yearly_avg_mag = df.groupby('year')['Magnitude'].mean()\n",
    "ax6.plot(yearly_avg_mag.index, yearly_avg_mag.values, marker='s', linewidth=2, color='red')\n",
    "ax6.set_xlabel('Year')\n",
    "ax6.set_ylabel('Average Magnitude')\n",
    "ax6.set_title('Average Magnitude by Year', fontsize=12, fontweight='bold')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Temporal Pattern Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}temporal_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Pattern Insights\n",
    "\n",
    "**Key Findings:**\n",
    "- **Increasing trend in recorded earthquakes** over time (improved detection capabilities)\n",
    "- **No significant monthly or weekly seasonality** - earthquakes are a natural phenomenon unrelated to calendar\n",
    "- **Uniform hourly distribution** confirms earthquakes occur randomly throughout the day\n",
    "- The year-month heatmap shows some years with elevated activity (potentially aftershock sequences)\n",
    "\n",
    "**Interpretation:**\n",
    "- The upward trend reflects improved seismic monitoring networks, not actual increase in earthquakes\n",
    "- More stations = ability to detect smaller earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Multivariate Analysis\n",
    "\n",
    "Examining relationships among multiple variables simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Correlation Matrix (Key Deliverable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "num_cols = ['Latitude', 'Longitude', 'Depth', 'Magnitude',\n",
    "            'nst', 'gap', 'rms', 'horizontalError', 'depthError',\n",
    "            'year', 'month', 'hour', 'energy']\n",
    "available_cols = [col for col in num_cols if col in df.columns]\n",
    "\n",
    "df_numeric = df[available_cols].dropna()\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "# Mask upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
    "            cmap='coolwarm', center=0, square=True,\n",
    "            linewidths=0.5, cbar_kws={'shrink': 0.8},\n",
    "            annot_kws={'size': 8}, ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Matrix - Numerical Variables', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find strongest correlations\n",
    "corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_pairs.append({\n",
    "            'var1': corr_matrix.columns[i],\n",
    "            'var2': corr_matrix.columns[j],\n",
    "            'correlation': corr_matrix.iloc[i, j]\n",
    "        })\n",
    "\n",
    "corr_df = pd.DataFrame(corr_pairs)\n",
    "corr_df['abs_corr'] = corr_df['correlation'].abs()\n",
    "top_corrs = corr_df.nlargest(10, 'abs_corr')\n",
    "\n",
    "print(\"Top 10 Strongest Correlations:\")\n",
    "for _, row in top_corrs.iterrows():\n",
    "    print(f\"  {row['var1']} <-> {row['var2']}: {row['correlation']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix Insights\n",
    "\n",
    "**Strongest Correlations:**\n",
    "1. **Magnitude - RMS (0.58)**: Larger earthquakes produce more scattered waveforms\n",
    "2. **Longitude - Magnitude (0.54)**: Geographic clustering of larger earthquakes\n",
    "3. **Magnitude - Horizontal Error (0.53)**: Location uncertainty increases with magnitude\n",
    "4. **Latitude - Longitude (-0.47)**: Reflects the shape of seismically active regions\n",
    "\n",
    "**Quality Metric Correlations:**\n",
    "- Higher station counts (nst) improve location precision\n",
    "- Azimuthal gap affects depth error estimation\n",
    "\n",
    "**Weak/No Correlations:**\n",
    "- Temporal variables (year, month, hour) show minimal correlation with seismic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 PCA Analysis (Key Deliverable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Analysis\n",
    "pca_cols = ['Latitude', 'Longitude', 'Depth', 'Magnitude',\n",
    "            'nst', 'gap', 'rms', 'horizontalError', 'depthError', 'energy']\n",
    "available_cols = [col for col in pca_cols if col in df.columns]\n",
    "\n",
    "# Prepare data\n",
    "df_pca = df[available_cols].dropna()\n",
    "\n",
    "# Keep magnitude category for coloring\n",
    "if 'magnitude_category' in df.columns:\n",
    "    idx = df_pca.index\n",
    "    mag_cat = df.loc[idx, 'magnitude_category']\n",
    "else:\n",
    "    mag_cat = None\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_pca)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Calculate variance explained\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(var_explained)\n",
    "\n",
    "n_components_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
    "\n",
    "print(f\"PCA Summary:\")\n",
    "print(f\"  Components for 95% variance: {n_components_95}\")\n",
    "print(f\"  First 3 PCs explain: {cumulative_var[2]*100:.1f}% variance\")\n",
    "print(f\"\\n  Variance by component:\")\n",
    "for i, (var, cum) in enumerate(zip(var_explained[:5], cumulative_var[:5])):\n",
    "    print(f\"    PC{i+1}: {var*100:.1f}% (cumulative: {cum*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Visualization\n",
    "fig = plt.figure(figsize=FIGSIZE_XLARGE)\n",
    "\n",
    "# Scree plot\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.bar(range(1, len(var_explained) + 1), var_explained * 100,\n",
    "        alpha=0.7, color='steelblue', label='Individual')\n",
    "ax1.plot(range(1, len(var_explained) + 1), cumulative_var * 100,\n",
    "         'ro-', linewidth=2, label='Cumulative')\n",
    "ax1.axhline(y=95, color='gray', linestyle='--', label='95% threshold')\n",
    "ax1.axvline(x=n_components_95, color='green', linestyle='--',\n",
    "            label=f'{n_components_95} components for 95%')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Variance Explained (%)')\n",
    "ax1.set_title('Scree Plot', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=8)\n",
    "\n",
    "# Cumulative variance\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.fill_between(range(1, len(cumulative_var) + 1), cumulative_var * 100, alpha=0.3)\n",
    "ax2.plot(range(1, len(cumulative_var) + 1), cumulative_var * 100, 'b-o', linewidth=2)\n",
    "ax2.axhline(y=95, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Variance Explained (%)')\n",
    "ax2.set_title('Cumulative Variance Explained', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2D scatter of PC1 vs PC2\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "# Sample for visualization\n",
    "if len(X_pca) > 10000:\n",
    "    sample_idx = np.random.choice(len(X_pca), 10000, replace=False)\n",
    "    X_pca_sample = X_pca[sample_idx]\n",
    "    mag_cat_sample = mag_cat.iloc[sample_idx] if mag_cat is not None else None\n",
    "else:\n",
    "    X_pca_sample = X_pca\n",
    "    mag_cat_sample = mag_cat\n",
    "\n",
    "if mag_cat_sample is not None:\n",
    "    cat_order = ['Micro', 'Minor', 'Small', 'Light', 'Moderate', 'Strong', 'Major', 'Great']\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.1, 0.9, len(cat_order)))\n",
    "    color_map = {cat: colors[i] for i, cat in enumerate(cat_order)}\n",
    "    \n",
    "    for cat in cat_order:\n",
    "        mask = mag_cat_sample == cat\n",
    "        if mask.sum() > 0:\n",
    "            ax3.scatter(X_pca_sample[mask, 0], X_pca_sample[mask, 1],\n",
    "                       alpha=0.5, s=10, label=cat, color=color_map.get(cat, 'gray'))\n",
    "    ax3.legend(title='Category', fontsize=8, bbox_to_anchor=(1.02, 1))\n",
    "else:\n",
    "    ax3.scatter(X_pca_sample[:, 0], X_pca_sample[:, 1], alpha=0.3, s=5)\n",
    "\n",
    "ax3.set_xlabel(f'PC1 ({var_explained[0]*100:.1f}%)')\n",
    "ax3.set_ylabel(f'PC2 ({var_explained[1]*100:.1f}%)')\n",
    "ax3.set_title('PCA - First Two Components', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Loadings heatmap\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(len(pca.components_))],\n",
    "    index=available_cols\n",
    ")\n",
    "loadings_display = loadings.iloc[:, :5]\n",
    "sns.heatmap(loadings_display, cmap='RdBu_r', center=0, annot=True,\n",
    "            fmt='.2f', ax=ax4, annot_kws={'size': 8})\n",
    "ax4.set_title('Feature Loadings (First 5 PCs)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('PCA Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}pca_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Analysis Insights\n",
    "\n",
    "**Variance Explained:**\n",
    "- **PC1 (29.7%)**: Primarily captures magnitude-related variation (magnitude, energy, rms)\n",
    "- **PC2 (13.8%)**: Primarily captures location-related variation (latitude, longitude)\n",
    "- **PC3 (11.1%)**: Captures depth-related variation\n",
    "- **9 components** needed to explain 95% of variance\n",
    "\n",
    "**Feature Loadings:**\n",
    "- Magnitude, energy, and RMS load heavily on PC1\n",
    "- Geographic coordinates (Lat, Lon) define PC2\n",
    "- Quality metrics (gap, errors) contribute to later components\n",
    "\n",
    "**2D Projection:**\n",
    "- Clear separation by magnitude category along PC1 axis\n",
    "- Larger earthquakes cluster on the right side of the projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Geospatial Analysis\n",
    "\n",
    "Analyzing the geographic distribution of earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earthquake locations map\n",
    "if len(df) > 50000:\n",
    "    df_sample = df.sample(n=50000, random_state=42)\n",
    "else:\n",
    "    df_sample = df\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_LARGE)\n",
    "\n",
    "if 'magnitude_category' in df_sample.columns:\n",
    "    cat_order = ['Micro', 'Minor', 'Small', 'Light', 'Moderate', 'Strong', 'Major', 'Great']\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.1, 0.9, len(cat_order)))\n",
    "    color_map = {cat: colors[i] for i, cat in enumerate(cat_order)}\n",
    "    \n",
    "    for cat in cat_order:\n",
    "        subset = df_sample[df_sample['magnitude_category'] == cat]\n",
    "        if len(subset) > 0:\n",
    "            size_scale = (cat_order.index(cat) + 1) * 2\n",
    "            ax.scatter(subset['Longitude'], subset['Latitude'],\n",
    "                      alpha=0.4, s=size_scale, label=cat,\n",
    "                      color=color_map.get(cat, 'gray'))\n",
    "    \n",
    "    ax.legend(title='Magnitude', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)\n",
    "else:\n",
    "    scatter = ax.scatter(df_sample['Longitude'], df_sample['Latitude'],\n",
    "                        c=df_sample['Magnitude'], cmap='YlOrRd',\n",
    "                        alpha=0.4, s=5)\n",
    "    plt.colorbar(scatter, ax=ax, label='Magnitude')\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Global Earthquake Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}earthquake_locations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earthquake density heatmap\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_LARGE)\n",
    "\n",
    "h = ax.hist2d(df['Longitude'], df['Latitude'],\n",
    "              bins=[180, 90], cmap='hot_r', cmin=1)\n",
    "\n",
    "plt.colorbar(h[3], ax=ax, label='Earthquake Count')\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Earthquake Density Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}earthquake_density.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Analysis Insights\n",
    "\n",
    "**Key Observations:**\n",
    "- Earthquakes are concentrated along **tectonic plate boundaries**\n",
    "- Clear visibility of the **Pacific Ring of Fire** (high earthquake density)\n",
    "- **Western US (California, Alaska)** shows high concentration of small earthquakes\n",
    "- **Asia-Pacific region** has both frequent and large earthquakes\n",
    "\n",
    "**Major Seismically Active Regions:**\n",
    "1. **Alaska/North Pacific**: 946,527 events (high frequency, moderate magnitudes)\n",
    "2. **Americas (West Coast)**: 1,595,101 events (highest count, mostly small)\n",
    "3. **Asia/Pacific**: 210,166 events (highest average magnitude: 4.38)\n",
    "4. **Europe/Africa**: 64,933 events (Mediterranean fault systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Key Findings and Conclusions\n",
    "\n",
    "### Summary of Key Findings\n",
    "\n",
    "#### Data Quality\n",
    "- Dataset contains **2,921,770 earthquake records** from 2002-2025\n",
    "- Missing values are minimal (<7.2% in any column)\n",
    "- Data quality is high with consistent geographic and temporal coverage\n",
    "\n",
    "#### Magnitude Distribution\n",
    "- **Right-skewed distribution** following Gutenberg-Richter law\n",
    "- Mean: 1.72, Median: 1.40\n",
    "- 97.4% of earthquakes are \"Small\" (M < 4)\n",
    "- Major earthquakes (M >= 7) are extremely rare (0.01%)\n",
    "\n",
    "#### Depth Distribution  \n",
    "- Majority of earthquakes are **shallow** (<70 km)\n",
    "- Mean depth: 24.8 km, Median: 8.6 km\n",
    "- Deep earthquakes (>300 km) are rare and associated with subduction zones\n",
    "\n",
    "#### Depth-Magnitude Relationship\n",
    "- **Moderate positive correlation** (r = 0.35, rho = 0.44)\n",
    "- Deeper earthquakes tend to be larger (partially due to detection bias)\n",
    "\n",
    "#### Temporal Patterns\n",
    "- **Increasing trend** in recorded earthquakes (improved monitoring)\n",
    "- No seasonal or weekly patterns (natural phenomenon)\n",
    "- Uniform hourly distribution\n",
    "\n",
    "#### Multivariate Analysis\n",
    "- Strong correlations: Magnitude-Energy, Magnitude-RMS, Location-Magnitude\n",
    "- **PCA**: 3 components explain 54.6% variance; 9 components for 95%\n",
    "- PC1 captures magnitude-related variation, PC2 captures location\n",
    "\n",
    "#### Geospatial Distribution\n",
    "- Earthquakes concentrated along **plate boundaries**\n",
    "- **Pacific Ring of Fire** is the most active region\n",
    "- Alaska and Western Americas have highest event counts\n",
    "- Asia-Pacific has highest average magnitude events\n",
    "\n",
    "### Recommendations for Further Analysis\n",
    "\n",
    "1. **Time Series Forecasting**: Analyze earthquake frequency trends for prediction\n",
    "2. **Clustering Analysis**: Identify aftershock sequences and spatial clusters\n",
    "3. **Machine Learning**: Build models to predict magnitude from other features\n",
    "4. **Risk Assessment**: Combine with population data for hazard mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Earthquakes Analyzed: {len(df):,}\")\n",
    "print(f\"Time Period: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"Magnitude Range: {df['Magnitude'].min():.1f} - {df['Magnitude'].max():.1f}\")\n",
    "print(f\"Depth Range: {df['Depth'].min():.1f} - {df['Depth'].max():.1f} km\")\n",
    "print(f\"\\nVisualizations Generated: 18 figures\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nEDA Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
